

- [ ] 预处理
- [x] 网络结构
- [ ] 各种卷积及其感受野
- [x] 激活函数
- [x] 权重初始化
- [x] 正向传播（DNN，CNN）
- [x] 反向传播（DNN，CNN）
- [ ] 损失函数
- [x] 优化器
- [ ] 超参数调节
- [x] 模型大小及其计算量计算
- [x] Batch Normalization

[卷积神经网络各层的学习率该如何增加？ - 知乎](https://www.zhihu.com/question/291795859)

[深度学习中的batch的大小对学习效果有何影响？ - 知乎](https://www.zhihu.com/question/32673260?sort=created)

重磅！图像分类相关文献/代码大列表 - 红色石头的文章 - 知乎
https://zhuanlan.zhihu.com/p/57003557





kaggle、天池比赛别想着去编，编不出来的，稍微问深一点你就蒙蔽了。1、在比赛中，你打的比赛是什么类型，数据集给的什么，哪些表格，包括了大概哪些特征，2、你怎么构建训练集，测试集，为什么这样构建，模型你选用了什么之后又换了什么，为什么这样选，3、比赛中你遇见了什么问题，如何解决这些问题 等等。 这东西不是编的出来的，比赛中你到底做了啥就写啥







面试题：

- [ ] 复现模型
- [ ] 手写BN
- [ ] 以xx loss为例子，推导BP算法
- [ ] 给出LR算法cost function的推导过程
- [ ] LR实现多分类
- [ ] 天池比赛



比赛创新点， 收获

## defense赛道



## attack赛道



