[TOC]

# 可视化





## 特征图可视化

Visualize Layer Activations

CNN学习到的特征呈现分层特性，底层是一些边缘角点以及颜色的抽象特征，越到高层则越呈现出具体的特征，这一过程正与人类视觉系统类似。这也为如何得到更好的模型给出了指导，一个最简单的思路便是使网络更深，使得每层的特征更加层次分明，这样就能学到更加泛化的特征，后来的VGGNet以及ResNet则证明了这一点。





单独可视化特征图的每个通道？



那么如何得到网络每一层的输出呢？



register_forward_hook

神经网络的每一个层都会调用一个hook函数，默认是没有的？ 我们可以注册这个hook函数（自己定义一个函数），这个函数的参数是(module, input, output), 这就允许我们得到每一层的输出， 我们可以在hook函数中print每一层的输出，或者是把每一层的输出存储下来。





### 结论

* 第一层是各种边缘检测器的集合。在这个阶段，激活值（特征图）几乎保留了原始图像中的所有信息。
* 随着层数的加深，激活变得越来越抽象，并且越来越难以直观地理解。它们开始表示更加高层次的概念，比如“猫耳朵”和“猫眼睛“。层数越深，其表示中关于图像视觉内容的信息就越少，而关于类别的信息就越多。
* 激活的稀疏度（sparsity）随着层数的加深而增大。在第一层里，所有过滤器都被输入图像激活，但是在后面的层里，越来越多的过滤器是空白的，也就说说，输入图像中找不到这些过滤器所编码的模式。



所以神经网络所学到的representation的一个重要性质就是：随着层数的加深，层所提取的特征越来越抽象，越来越高级。更高层的激活包含原始输入的信息越来越少，而关于目标的信息越来越多（比如猫啊，狗啊）。深度神经网络可以有效地作为__信息蒸馏管道__（information distillation pipeline），输入原始数据，反复对其变换，将无关的信息过滤掉（比如图像的外观），并放大和细化有用的信息（比如图像类别）。







## 权重可视化

Visualize Layer Weights

其思想和对抗攻击类似，或者说对抗攻击的思想和权重可视化的思想一致。

例如我们想要可视化某一层的某个卷积核，其大小为$C_{in} \times 3 \times 3$，并不好直接对其可视化。而是使用梯度优化的思想对其可视化，该卷积核对输入的特征图进行卷积后得到一个特征图，我们希望该特征图的值越大越好，实际上是该特征图的均值越大越好。若使用激活函数ReLU，若特征图的值小于0，那么经过激活之后，因为抑制从而为0，进一步导致特征图为0。

所以，我们可以用该卷积核输出的特征图的均值为损失函数，我们希望最大化该损失函数，从而去优化输入。优化之后，我们便知道该卷积核期望的输入是什么，也急输入是什么时，该卷积核被激活。



此处应该有图像。



可以看到，低层的卷积核期望的输入类似边缘，纹理之类。而高层的卷积核期望的输入是更加高级的特征。

并且，这些可视化权重得到的图像内容具有重复性，这是显然的，因为特征图是通过卷积核卷积（在输入特征图上滑动）得到的，那么当然期望输入具有重复性才会最大化损失函数。



当然了，实际上的训练图像，并没有那么多高级的重复特征。所以，实际上的图像在经过高层的卷积后得到的特征图，只有某些位置被激活了，__也即每个特征图的内容具有稀疏性质__。并且，若输入的图像并不是该卷积核所期望的，那么可能就会导致其输出的特征图为空，__也即输出特征图的稀疏性__。









[pytorch-cnn-visualizations, github code](https://github.com/utkuozbulak/pytorch-cnn-visualizations)

[visualizing-cnn-feature-maps, github code](https://github.com/fg91/visualizing-cnn-feature-maps)

[40行Python代码，实现卷积特征可视化](https://www.jiqizhixin.com/articles/2019-01-31-13)





## 类激活热力图可视化



类激活热力图是与__特定输出类别__相关的二维分数图，对任何输入图像的每个位置都要进行计算，它表示每个位置对该类别的重要程度。





“Grad-CAM: visual explanations from deep networks via gradientbased localization中说了如何实现类激活热力图可视化。给定一张输入图像，对于一个卷积层的输出特征图，用类别相对于通道的梯度对这个特征图中的每个通道进行加权。



对于某张图像，假设其属于第10类，将其通过神经网络，得到第10类的logits（该值越大越好），将该logit对某一个卷积层所输出的特征图进行求导。















## t-SNE

An Introduction to t-SNE with Python Example

https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1





CNN的一些可视化方法 - yishun的文章 - 知乎
https://zhuanlan.zhihu.com/p/53683453



深度学习调参有哪些技巧？ - 杨军的回答 - 知乎
https://www.zhihu.com/question/25097993/answer/127374415



进大厂全靠自学，微软&头条实习生现身说法：我是这样自学深度学习的丨课程传送门 - 量子位的文章 - 知乎
https://zhuanlan.zhihu.com/p/68990173





凭什么相信你，我的CNN模型？（篇一：CAM和Grad-CAM)

https://www.jianshu.com/p/1d7b5c4ecb93



作者：杨军

谷歌的新CNN特征可视化方法，构造出一个华丽繁复的新世界

 https://www.leiphone.com/news/201711/aNw8ZjqMuqvygzlz.html









References:
[1]. Visualizing what ConvNets Learn. CS231n Convolutional Neural Networks for Visual RecognitionCS231n Convolutional Neural Networks for Visual Recognition[2]. Matthew Zeiler. Visualizing and Understanding Convolutional Networks. Visualizing and Understanding Convolutional Networks.
[3]. Daniel Bruckner. deepViz: Visualizing Convolutional Neural Networks for Image Classification. 
http://vis.berkeley.edu/courses/cs294-10-fa13/wiki/images/f/fd/DeepVizPaper.pdf

[4]. ConvNetJS MNIST Demo. ConvNetJS MNIST demo

[5]. Receptive Field. CS231n Convolutional Neural Networks for Visual Recognition

[6]. Receptive Field of Neurons in LeNet. deep learning

[7]. Ross Girshick. Rich feature hierarchies for accurate object detection and semantic segmentation
Tech report. Arxiv, 2011.
[8]. CS231n: Convolutional Neural Networks for Visual Recognition. Stanford University CS231n: Convolutional Neural Networks for Visual Recognition

[9]. Christian Szegedy. Intriguing properties of neural networks. Arxiv, 2013.
[10]. t-SNE. t-SNE – Laurens van der Maaten

[11]. Matthew D.Zeiler. Visualizing and Understanding Convolutional Networks. Arxiv, 2011.
[12]. Matthew D.Zeiler. Adaptive Deconvolutional Networks for Mid and High Level Feature Learning, ICCV 2011. 
[13]. Neural Networks Part 3: Learning and Evaluation. CS231n Convolutional Neural Networks for Visual Recognition

[14]. ConvNetJS---Deep Learning in Your Browser.ConvNetJS: Deep Learning in your browser

[15]. Colah. Visualizing MNIST: An Exploration of Dimensionality Reduction.